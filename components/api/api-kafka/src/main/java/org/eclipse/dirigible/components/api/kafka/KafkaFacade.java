/*
 * Copyright (c) 2023 SAP SE or an SAP affiliate company and Eclipse Dirigible contributors
 *
 * All rights reserved. This program and the accompanying materials are made available under the
 * terms of the Eclipse Public License v2.0 which accompanies this distribution, and is available at
 * http://www.eclipse.org/legal/epl-v20.html
 *
 * SPDX-FileCopyrightText: 2023 SAP SE or an SAP affiliate company and Eclipse Dirigible
 * contributors SPDX-License-Identifier: EPL-2.0
 */

package org.eclipse.dirigible.components.api.kafka;

import java.util.Collections;
import java.util.HashMap;
import java.util.Map;
import java.util.Properties;

import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.eclipse.dirigible.commons.api.helpers.GsonHelper;
import org.eclipse.dirigible.commons.config.Configuration;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Component;

/**
 * The Class KafkaFacade.
 */
@Component
public class KafkaFacade {

    /** The Constant DIRIGIBLE_KAFKA_BOOTSTRAP_SERVER. */
    private static final String DIRIGIBLE_KAFKA_BOOTSTRAP_SERVER = "DIRIGIBLE_KAFKA_BOOTSTRAP_SERVER";

    /** The Constant DIRIGIBLE_KAFKA_ACKS. */
    private static final String DIRIGIBLE_KAFKA_ACKS = "DIRIGIBLE_KAFKA_ACKS";

    /** The Constant DIRIGIBLE_KAFKA_KEY_SERIALIZER. */
    private static final String DIRIGIBLE_KAFKA_KEY_SERIALIZER = "DIRIGIBLE_KAFKA_KEY_SERIALIZER";

    /** The Constant DIRIGIBLE_KAFKA_VALUE_SERIALIZER. */
    private static final String DIRIGIBLE_KAFKA_VALUE_SERIALIZER = "DIRIGIBLE_KAFKA_VALUE_SERIALIZER";

    /** The Constant DIRIGIBLE_KAFKA_AUTOCOMMIT_ENABLED. */
    private static final String DIRIGIBLE_KAFKA_AUTOCOMMIT_ENABLED = "DIRIGIBLE_KAFKA_AUTOCOMMIT_ENABLED";

    /** The Constant DIRIGIBLE_KAFKA_AUTOCOMMIT_INTERVAL. */
    private static final String DIRIGIBLE_KAFKA_AUTOCOMMIT_INTERVAL = "DIRIGIBLE_KAFKA_AUTOCOMMIT_INTERVAL";


    /** The Constant DEFAULT_BOOTSTRAP_SERVER. */
    private static final String DEFAULT_BOOTSTRAP_SERVER = "localhost:9092";

    /** The Constant DIRIGIBLE_KAFKA_ACKS_ALL. */
    private static final String DIRIGIBLE_KAFKA_ACKS_ALL = "all";

    /** The Constant DIRIGIBLE_KAFKA_SERIALIZER_STRING. */
    private static final String DIRIGIBLE_KAFKA_SERIALIZER_STRING = "org.apache.kafka.common.serialization.StringSerializer";

    /** The Constant DIRIGIBLE_KAFKA_AUTOCOMMIT_ENABLED_DEFAULT. */
    private static final String DIRIGIBLE_KAFKA_AUTOCOMMIT_ENABLED_DEFAULT = "true";

    /** The Constant DIRIGIBLE_KAFKA_AUTOCOMMIT_INTERVAL_DEFAULT. */
    private static final String DIRIGIBLE_KAFKA_AUTOCOMMIT_INTERVAL_DEFAULT = "1000";


    /** The Constant logger. */
    private static final Logger logger = LoggerFactory.getLogger(KafkaFacade.class);

    /** The producers. */
    private static Map<String, Producer<String, String>> PRODUCERS = Collections.synchronizedMap(new HashMap());

    /** The consumers. */
    private static Map<String, KafkaConsumerRunner> CONSUMERS = Collections.synchronizedMap(new HashMap());

    /**
     * Send a key-value pair to a topic.
     *
     * @param destination the destination
     * @param key the key
     * @param value the value
     * @param configuration the configuration
     */
    public static final void send(String destination, String key, String value, String configuration) {
        if (configuration == null) {
            configuration = "{}";
        }

        Map map = GsonHelper.fromJson(configuration, Map.class);
        Producer<String, String> producer = null;

        String bootstrapServer = Configuration.get(DIRIGIBLE_KAFKA_BOOTSTRAP_SERVER, DEFAULT_BOOTSTRAP_SERVER);
        String server = map.get("bootstrap.servers") != null ? map.get("bootstrap.servers")
                                                                  .toString()
                : bootstrapServer;
        if (server != null) {
            producer = PRODUCERS.get(server);
        }

        if (producer == null) {
            Properties props = new Properties();
            for (Object k : map.keySet()) {
                props.put(k, map.get(k));
            }
            if (props.get("bootstrap.servers") == null) {
                // default to localhost
                props.put("bootstrap.servers", bootstrapServer);
            }
            if (props.get("acks") == null) {
                // default to all
                String acks = Configuration.get(DIRIGIBLE_KAFKA_ACKS, DIRIGIBLE_KAFKA_ACKS_ALL);
                props.put("acks", acks);
            }
            if (props.get("key.serializer") == null) {
                // default to org.apache.kafka.common.serialization.StringSerializer
                String keySerializer = Configuration.get(DIRIGIBLE_KAFKA_KEY_SERIALIZER, DIRIGIBLE_KAFKA_SERIALIZER_STRING);
                props.put("key.serializer", keySerializer);
            }
            if (props.get("value.serializer") == null) {
                // default to org.apache.kafka.common.serialization.StringSerializer
                String valueSerializer = Configuration.get(DIRIGIBLE_KAFKA_VALUE_SERIALIZER, DIRIGIBLE_KAFKA_SERIALIZER_STRING);
                props.put("value.serializer", valueSerializer);
            }
            producer = new KafkaProducer<>(props);
            PRODUCERS.put(server, producer);
            if (logger.isInfoEnabled()) {
                logger.info("Kafka Producer [{}] created.", server);
            }
        }

        producer.send(new ProducerRecord<String, String>(destination, key, value));

        // producer.close();
    }

    /**
     * Close the producer per server endpoint.
     *
     * @param configuration the configuration
     */
    public static final void closeProducer(String configuration) {
        if (configuration == null) {
            configuration = "{}";
        }

        Map map = GsonHelper.fromJson(configuration, Map.class);
        Producer<String, String> producer = null;

        String bootstrapServer = Configuration.get(DIRIGIBLE_KAFKA_BOOTSTRAP_SERVER, DEFAULT_BOOTSTRAP_SERVER);
        String server = map.get("bootstrap.servers") != null ? map.get("bootstrap.servers")
                                                                  .toString()
                : bootstrapServer;
        if (server != null) {
            producer = PRODUCERS.get(server);
        }

        if (producer != null) {
            producer.close();
            PRODUCERS.remove(server);
        } else {
            if (logger.isWarnEnabled()) {
                logger.warn("Kafka Producer [{}] has not been started yet.", server);
            }
        }
    }

    /**
     * Start listening.
     *
     * @param destination the destination
     * @param handler the handler
     * @param timeout the timeout
     * @param configuration the configuration
     */
    public static final void startListening(String destination, String handler, int timeout, String configuration) {
        if (configuration == null) {
            configuration = "{}";
        }

        Map map = GsonHelper.fromJson(configuration, Map.class);

        Consumer<String, String> consumer = null;
        KafkaConsumerRunner consumerRunner = null;

        String location = null;
        String bootstrapServer = Configuration.get(DIRIGIBLE_KAFKA_BOOTSTRAP_SERVER, DEFAULT_BOOTSTRAP_SERVER);
        String server = map.get("bootstrap.servers") != null ? map.get("bootstrap.servers")
                                                                  .toString()
                : bootstrapServer;
        location = createLocation(destination, server);
        consumerRunner = CONSUMERS.get(location);

        if (consumerRunner == null) {
            Properties props = new Properties();
            for (Object k : map.keySet()) {
                props.put(k, map.get(k));
            }
            if (props.get("bootstrap.servers") == null) {
                // default to localhost
                props.put("bootstrap.servers", bootstrapServer);
            }
            if (props.get("group.id") == null) {
                // default to handler
                props.put("group.id", handler != null ? handler : destination);
            }
            if (props.get("enable.auto.commit") == null) {
                // autocommit
                String enableAutoCommit = Configuration.get(DIRIGIBLE_KAFKA_AUTOCOMMIT_ENABLED, DIRIGIBLE_KAFKA_AUTOCOMMIT_ENABLED_DEFAULT);
                props.put("enable.auto.commit", enableAutoCommit);
            }
            if (props.get("auto.commit.interval.ms") == null) {
                // autocommit interval 1000
                String autoCommitInterval =
                        Configuration.get(DIRIGIBLE_KAFKA_AUTOCOMMIT_INTERVAL, DIRIGIBLE_KAFKA_AUTOCOMMIT_INTERVAL_DEFAULT);
                props.put("auto.commit.interval.ms", autoCommitInterval);
            }
            if (props.get("key.deserializer") == null) {
                // default to org.apache.kafka.common.serialization.StringSerializer
                String keySerializer = Configuration.get(DIRIGIBLE_KAFKA_KEY_SERIALIZER, DIRIGIBLE_KAFKA_SERIALIZER_STRING);
                props.put("key.deserializer", keySerializer);
            }
            if (props.get("value.deserializer") == null) {
                // default to org.apache.kafka.common.serialization.StringSerializer
                String valueSerializer = Configuration.get(DIRIGIBLE_KAFKA_VALUE_SERIALIZER, DIRIGIBLE_KAFKA_SERIALIZER_STRING);
                props.put("value.deserializer", valueSerializer);
            }

            consumer = new KafkaConsumer<>(props);

            consumerRunner = new KafkaConsumerRunner(consumer, destination, handler, timeout);
            Thread consumerThread = new Thread(consumerRunner);
            consumerThread.setDaemon(false);
            consumerThread.start();
            CONSUMERS.put(location, consumerRunner);
            if (logger.isInfoEnabled()) {
                logger.info("Kafka Consumer [{}] created.", location);
            }
        } else {
            if (logger.isWarnEnabled()) {
                logger.warn("Kafka Consumer [{}] has already been started.", location);
            }
        }
    }

    /**
     * Stop listening.
     *
     * @param destination the destination
     * @param configuration the configuration
     */
    public static final void stopListening(String destination, String configuration) {
        if (configuration == null) {
            configuration = "{}";
        }

        Map map = GsonHelper.fromJson(configuration, Map.class);

        KafkaConsumerRunner consumerRunner = null;

        String location = null;
        String bootstrapServer = Configuration.get(DIRIGIBLE_KAFKA_BOOTSTRAP_SERVER, DEFAULT_BOOTSTRAP_SERVER);
        String server = map.get("bootstrap.servers") != null ? map.get("bootstrap.servers")
                                                                  .toString()
                : bootstrapServer;
        location = createLocation(destination, server);
        consumerRunner = CONSUMERS.get(location);

        if (consumerRunner != null) {
            consumerRunner.stop();
            CONSUMERS.remove(location);
        } else {
            if (logger.isWarnEnabled()) {
                logger.warn("Kafka Consumer [" + location + "] has not been started yet.");
            }
        }
    }

    /**
     * Create internal identifier for a consumer.
     *
     * @param destination the destination
     * @param server the server
     * @return the identifier
     */
    private static String createLocation(String destination, String server) {
        return "[" + server + "]:[" + destination + "]";
    }

}
